{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/annariha/StanCon-2024-BO-Stan/blob/main/template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimisation using Stan @ StanCon 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Use a repository of pre-built package binaries to speed-up installation\n",
    "download.file(\"https://github.com/eddelbuettel/r2u/raw/master/inst/scripts/add_cranapt_jammy.sh\",\n",
    "              \"add_cranapt_jammy.sh\")\n",
    "Sys.chmod(\"add_cranapt_jammy.sh\", \"0755\")\n",
    "system(\"./add_cranapt_jammy.sh\")\n",
    "\n",
    "# Install R Packages\n",
    "install.packages(c(\"here\", \"tidyverse\", \"ggplot2\", \"MASS\", \"cmdstanr\"),\n",
    "                  repos = c(\"https://stan-dev.r-universe.dev\", getOption(\"repos\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this tutorial, we use the [cmdstanr](https://mc-stan.org/cmdstanr/articles/cmdstanr.html) R interface to CmdStan. We install and setup CmdStan as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Install and setup CmdStan\n",
    "download.file(\"https://github.com/stan-dev/cmdstan/releases/download/v2.35.0/colab-cmdstan-2.35.0.tgz\",\n",
    "              \"cmdstan-2.35.0.tgz\")\n",
    "utils::untar(\"cmdstan-2.35.0.tgz\")\n",
    "cmdstanr::set_cmdstan_path(\"cmdstan-2.35.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load all required libraries and set a seed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(here)\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(MASS)\n",
    "library(cmdstanr)\n",
    "\n",
    "set.seed(424242)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Icebreaker \n",
    "\n",
    "Imagine you only observe three function evaluations of an otherwise unknown function, and you want to find the global minimum of the function. \n",
    "\n",
    "How would you approach this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "observed_evals <- data.frame(x = c(0.2, 0.25, 0.95), y = c(-0.64, -0.21, 12.30))\n",
    "\n",
    "ggplot(data = observed_evals, aes(x = x, y = y)) +\n",
    "    geom_point() + \n",
    "    ylab(\"f(x)\") + \n",
    "    ylim(-5, 15) +\n",
    "    theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Introduction to Bayesian optimisation (BO)\n",
    "\n",
    "Luckily, we don't have to continue guessing what points to evaluate next. Bayesian optimisation to the rescue! \n",
    "\n",
    "The goal of BO is to find the minimum or maximum of an unknown function (\"black-box\") for which we can only obtain function evaluations at a finite number of points. \n",
    "\n",
    "There are many applications of BO ranging from hyperparameter discovery to experimental design. \n",
    "\n",
    "The BO mechanism makes use of a **surrogate model** and an **acquisition function** to efficiently navigate the trade-off between exploration and exploitation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Surrogate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One option for a surrogate model is a Gaussian process.  \n",
    "\n",
    "By definition of a GP, writing $g \\sim \\mathcal{GP}\\left(\\mu, K\\right)$ with mean function $\\mu(.)$ and a covariance or kernel function $K(.,.)$ means that the joint distribution of the functionâ€™s value $g(\\mathbf{x})$ at a finite number of input points $\\mathbf{x} = \\{x_1, \\cdots, x_n\\}$ is a multivariate normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different covariance functions for GPs are available in Stan and are listed in the [Stan function documentation](https://mc-stan.org/docs/functions-reference/matrix_operations.html#gaussian-process-covariance-functions). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate how to set up the different components of Bayesian optimisation using a GP with a squared exponential covariance function, assume that we want to find the minimum of the \"unknown\" function $f(x) = (6  x - 2)^2  \\sin(12  x - 4)$ (Forrester function). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "forrester_fun <- function(x) {\n",
    "  return((6 * x - 2)^2 * sin(12 * x - 4))\n",
    "}\n",
    "\n",
    "x_grid <- seq(0, 1, length.out = 100)\n",
    "\n",
    "plot_forrester <- ggplot(data = data.frame(x = x_grid, y = forrester_fun(x_grid)), aes(x = x, y = y)) +\n",
    "  geom_line() + \n",
    "  ylab(\"f(x)\") + \n",
    "  theme_bw()\n",
    "\n",
    "plot_forrester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start with the following GP surrogate for $f(x)$:  \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y &\\sim \\text{N}(g(x), \\sigma) \\ \\text{with} \\ \\sigma \\sim \\text{N}^+(0,1),\\\\\n",
    "\\\\\n",
    "g(x) &\\sim GP(\\mu, K),  \\text{with} \\ \\mu \\sim \\text{N}(0,1),\\\\ \n",
    "K_{i,j} &= k (x_i, x_j) = \\alpha^2  \\exp \\left(- \\frac{(x_i - x_j)^2}{\\rho^2} \\right),\\\\\n",
    "\\\\\n",
    "\\alpha &\\sim \\text{N}^+(0,1),\\\\ \n",
    "\\rho &\\sim \\text{N}(0.3,0.1).\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Stan, we can implement the model like this, using the covariance function `gp_exp_quad_cov`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "stan_1_gp <- \"\n",
    "data {\n",
    "  int<lower=1> N_obs;\n",
    "  array[N_obs] real x_obs;\n",
    "  vector[N_obs] y_obs;\n",
    "  int<lower=1> N_pred;\n",
    "  array[N_pred] real x_pred;\n",
    "}\n",
    "\n",
    "transformed data {\n",
    "  int<lower=1> N = N_obs + N_pred;\n",
    "  array[N] real x;\n",
    "  for (n_obs in 1:N_obs)   x[n_obs] = x_obs[n_obs];\n",
    "  for (n_pred in 1:N_pred) x[N_obs + n_pred] = x_pred[n_pred];\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real<lower=0> rho;\n",
    "  real<lower=0> alpha;\n",
    "  real<lower=0> sigma;\n",
    "  real mu;\n",
    "  vector[N] eta;\n",
    "}\n",
    "\n",
    "transformed parameters{\n",
    "  vector[N] g;\n",
    "  { \n",
    "    matrix[N, N] L;\n",
    "    matrix[N, N] K;\n",
    "    K = gp_exp_quad_cov(x, alpha, rho) + diag_matrix(rep_vector(1e-10, N));\n",
    "    L = cholesky_decompose(K);\n",
    "    g = mu + L * eta;\n",
    "  }\n",
    "}\n",
    "\n",
    "model {\n",
    "  rho   ~ normal(0.3,0.1);\n",
    "  alpha ~ std_normal();\n",
    "  sigma ~ std_normal();\n",
    "  mu    ~ std_normal();\n",
    "  eta   ~ std_normal();\n",
    "  y_obs ~ normal(g[1:N_obs], sigma);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "  vector[N_pred] y_pred;\n",
    "  for (n_pred in 1:N_pred){\n",
    "    y_pred[n_pred] = normal_rng(g[N_obs + n_pred], sigma);\n",
    "  }\n",
    "}\n",
    "\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this one implementation to get started, and there are other (more efficient) ways to set up and reparameterise GPs in Stan, see the comments by Andrew Johnson and Aki Vehtari in [Stan discourse](https://discourse.mc-stan.org/t/help-reparameterize-gp-model-to-remove-divergent-transitions/26425/4?u=andrjohns), Aki's case study on GPs [here](https://avehtari.github.io/casestudies/Motorcycle/motorcycle_gpcourse.html), and the computational tricks mentioned in the tutorial slides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Save Stan code in Stan file \n",
    "file_1_gp <- cmdstanr::write_stan_file(stan_1_gp, dir = \"Stan/\", basename = \"model_1_gp.stan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# To use the model, we first need to compile it\n",
    "model_1_gp <- cmdstanr::cmdstan_model(file_1_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the model to draw samples from our surrogate model, using the three function evaluations that we obtained previously as observations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Use the model \n",
    "\n",
    "# 1. Use the function evaluations provided above as input \n",
    "x_grid <- seq(0, 1, length.out = 100)\n",
    "sd_global <- sd(observed_evals$y)\n",
    "y_scaled <- observed_evals$y / sd_global\n",
    "\n",
    "stan_dat <- list(N_obs = NROW(observed_evals),\n",
    "                 x_obs = observed_evals$x,\n",
    "                 y_obs = y_scaled, \n",
    "                 N_pred = length(x_grid), \n",
    "                 x_pred = x_grid)\n",
    "\n",
    "# 2. Get samples from surrogate model\n",
    "gp_samples <- model_1_gp$sample(data = stan_dat,\n",
    "                                seed = 424242,\n",
    "                                iter_sampling = 500,\n",
    "                                parallel_chains = 4)\n",
    "\n",
    "# 3. Extract predictions\n",
    "g_draws <- gp_samples$draws(variables = \"g\", format = \"draws_matrix\")\n",
    "N_obs <- NROW(observed_evals)\n",
    "N_pred <- length(x_grid)\n",
    "g_pred <- t(g_draws[,(N_obs+1):(N_obs + N_pred)])\n",
    "# Rescale g_pred \n",
    "g_pred <- g_pred * sd_global\n",
    "# Get GP mean and sd \n",
    "gp_mean <- apply(g_pred, 1, mean) \n",
    "gp_sd <- apply(g_pred, 1, sd)\n",
    "\n",
    "# 5. Visualise \n",
    "plot_gp_1 <- plot_forrester + \n",
    "    geom_point(data = observed_evals, aes(x = x, y = y)) +\n",
    "    geom_line(aes(x = x_grid, y = gp_mean), colour = \"blue\") +\n",
    "    geom_line(aes(x = x_grid, y = gp_mean - 2*gp_sd), colour = \"blue\", linetype= \"dashed\") +\n",
    "    geom_line(aes(x = x_grid, y = gp_mean + 2*gp_sd), colour = \"blue\", linetype= \"dashed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's your turn: \n",
    "\n",
    "1. Adjust the above Stan code such that it uses the MatÃ©rn 3/2 covariance function instead;\n",
    "2. If you have been working in a code cell here, make sure to save the Stan code in a Stan file; \n",
    "3. Compile & use the model. \n",
    "\n",
    "The MatÃ©rn 3/2 covariance function is given by: \n",
    "\n",
    "$$k(\\mathbf{x}_i, \\mathbf{x}_j) = \\sigma^2 \\left( 1 + \\frac{\\sqrt{3}|\\mathbf{x}_i - \\mathbf{x}_j|}{l} \\right) \\exp \\left( -\\frac{\\sqrt{3}|\\mathbf{x}_i - \\mathbf{x}_j|}{l} \\right)$$\n",
    "\n",
    "Our model with MatÃ©rn covariance function, requires us to choose priors for the parameters magnitude $\\sigma$ and lengthscale $l$. Let's assume the following priors for now: \n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\mu &\\sim \\text{N}(0,1)\\\\\n",
    "\\eta &\\sim \\text{N}(0,1) \\\\\n",
    "\\sigma &\\sim \\text{N}^+(0,1)\\\\\n",
    "l &\\sim \\text{N}^+(0.3, 0.1)\n",
    "\\end{aligned} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Edit the Stan code wherever you see \"...\" to use the MatÃ©rn 3/2 covariance function \n",
    "stan_2_gp <- \"\n",
    "data {\n",
    "  int<lower=1> N_obs;\n",
    "  array[N_obs] real x_obs;\n",
    "  vector[N_obs] y_obs;\n",
    "  int<lower=1> N_pred;\n",
    "  array[N_pred] real x_pred;\n",
    "}\n",
    "\n",
    "transformed data {\n",
    "  int<lower=1> N = N_obs + N_pred;\n",
    "  array[N] real x;\n",
    "  for (n_obs in 1:N_obs)   x[n_obs] = x_obs[n_obs];\n",
    "  for (n_pred in 1:N_pred) x[N_obs + n_pred] = x_pred[n_pred];\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real<lower=0> ...;\n",
    "  real<lower=0> ...;\n",
    "  real mu;\n",
    "  vector[N] eta;\n",
    "}\n",
    "\n",
    "transformed parameters{\n",
    "  vector[N] g;\n",
    "  { \n",
    "    matrix[N, N] L;\n",
    "    matrix[N, N] K;\n",
    "    K = ...;\n",
    "    L = cholesky_decompose(K);\n",
    "    g = mu + L * eta;\n",
    "  }\n",
    "}\n",
    "\n",
    "model {\n",
    "  lengthscale ~ ...;\n",
    "  sigma ~ ...;\n",
    "  mu ~ std_normal();\n",
    "  eta ~ std_normal();\n",
    "  y_obs ~ normal(g[1:N_obs], sigma);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "  vector[N_pred] y_pred;\n",
    "  for (n_pred in 1:N_pred){\n",
    "    y_pred[n_pred] = normal_rng(g[N_obs + n_pred], sigma);\n",
    "  }\n",
    "}\n",
    "\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Save Stan code in Stan file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Use the model \n",
    "\n",
    "# 1. Use the same \"stan_dat\" provided above as input \n",
    "\n",
    "# 2. Get samples from surrogate model\n",
    "\n",
    "# 3. Extract predictions to get GP mean and sd \n",
    "\n",
    "# 4. Visualise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Acquisition functions\n",
    "\n",
    "An acquisition function $a(x)$ serves as a guide to efficiently decide where to query the unknown function next. Different considerations about the problem at hand can motivate choosing different acquisition functions, more details on this can be found in the tutorial slides. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### For example: Lower confidence bound \n",
    "\n",
    "$$\\text{a}(x) = \\mu(x) - \\kappa*\\sigma(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our obtained samples from the previous section, we choose $\\kappa=4$ and can then compute acquistion values to guide our next query: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "kappa = 4 \n",
    "acq_values_lcb <- gp_mean - kappa * gp_sd\n",
    "\n",
    "ggplot(data = data.frame(x = x_grid, y = acq_values_lcb), aes(x = x, y = y)) +\n",
    "  geom_line() +\n",
    "  ylab(\"acquisition function a(x)\") +\n",
    "  theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Towards cost- and response propensity-aware BO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Varying cost of queries\n",
    "\n",
    "We need to choose a **surrogate model** and an **acquisition function** to implement a BO loop. Additionally, there can be a **cost** associated with each query. Instead of assuming that all queries have the same cost, we can build our approach such that it accounts for varying cost of queries. \n",
    "\n",
    "Let's assume a periodic cost function $c(x)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cost_fun <- function(x){\n",
    "    1.5 - sin(16*x)\n",
    " }\n",
    "\n",
    "ggplot(data = data.frame(x = x_grid, cost = cost_fun(x_grid)), aes(x = x, y = cost)) +\n",
    "  geom_line() +\n",
    "  ylab(\"cost function c(x)\") +\n",
    "  theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we can add a step to the BO loop where we apply an amount of cost cooling $\\alpha$ to our cost function $c(x)$ and then combine this with the chosen acquisition function $a(x)$. Here, $\\alpha$ is dependent on the budget, the current cost and the initial cost:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "alpha_fun <- function(budget, current_cost, initial_cost){\n",
    "    (budget - current_cost)/(budget - initial_cost)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost-cooled acquisition function is $a_{\\text{cool}}(x) = \\frac{a(x)}{c(x)^{\\alpha}}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Propensity of response \n",
    "\n",
    "In some applications, it is important to account for the fact that we might not obtain a response at the point where we decided to query next. For example, if we send out a survey, there will be people that won't respond, and it might be that one group of people is overall less likely to respond than another, for example, based on age or gender. \n",
    "\n",
    "We can include this in the BO loop by combining our acquistion function $a(x)$ with a chosen propensity function $r(x)$. Here, we choose the following fluctuating propensity function $r(x)$ that is higher for smaller values of $x$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "propensity_fun <- function(x){\n",
    "    (2.4 + sin(13*x) + sin(44*(x+0.1))  + cos(5*x)) / 6\n",
    " }\n",
    "\n",
    "ggplot(data = data.frame(x = x_grid, y = propensity_fun(x_grid)), aes(x = x, y = y)) +\n",
    "  geom_line() +\n",
    "  ylab(\"propensity function r(x)\") +\n",
    "  theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The propensity-aware acquisition function is $a_{\\text{prop}}(x) = a(x)r(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Bringing it together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the chosen cost function $c(x)$, cost-cooling using $\\alpha$, and the propensity function $r(x)$ to build a cost- and response propensity-aware acquistion function: \n",
    "$$a_{\\text{prop,cool}}(x) = a_{\\text{cool}}(x) r(x) = \\frac{a(x)}{c(x)^{\\alpha}} r(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> possibly provide samples via GitHub & then ask to visualise \n",
    "\n",
    "-> Aalto file sharing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Wrap-up \n",
    "\n",
    "- query from us function evaluations\n",
    "- find the minimum of a function, but this time use the science youâ€™ve learnt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
