{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/annariha/StanCon-2024-BO-Stan/blob/main/template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimisation using Stan @ StanCon 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Use a repository of pre-built package binaries to speed-up installation\n",
    "download.file(\"https://github.com/eddelbuettel/r2u/raw/master/inst/scripts/add_cranapt_jammy.sh\",\n",
    "              \"add_cranapt_jammy.sh\")\n",
    "Sys.chmod(\"add_cranapt_jammy.sh\", \"0755\")\n",
    "system(\"./add_cranapt_jammy.sh\")\n",
    "\n",
    "# Install the R Packages we'll be using\n",
    "install.packages(c(\"here\", \"tidyverse\", \"bayesplot\", \"cmdstanr\"),\n",
    "                  repos = c(\"https://stan-dev.r-universe.dev\", getOption(\"repos\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this tutorial, we use the [cmdstanr](https://mc-stan.org/cmdstanr/articles/cmdstanr.html) R interface to CmdStan. We install and setup CmdStan as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Install and setup CmdStan\n",
    "download.file(\"https://github.com/stan-dev/cmdstan/releases/download/v2.35.0/colab-cmdstan-2.35.0.tgz\",\n",
    "              \"cmdstan-2.35.0.tgz\")\n",
    "utils::untar(\"cmdstan-2.35.0.tgz\")\n",
    "cmdstanr::set_cmdstan_path(\"cmdstan-2.35.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load all required libraries and set a seed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(cmdstanr)\n",
    "library(here)\n",
    "library(tidyverse)\n",
    "library(khroma)\n",
    "\n",
    "set.seed(424242)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Icebreaker \n",
    "\n",
    "Idea: show function evaluations & ask where to sample next to find globale minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Bayesian optimisation (BO)\n",
    "\n",
    " - goal of BO\n",
    " - where is it used in practice (use cases) → add model selection perspective\n",
    " - components of BO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surrogate models\n",
    "\n",
    "GP as a surrogate model\n",
    "- GP as a prior (and posterior) over functions \n",
    "- Exercise: implement your own kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquisition functions\n",
    "-> if I create a figure, put the code in the template such that participants can try\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (?) Computational Tricks for GPs \n",
    "\n",
    "- mention GP tricks: Kronecker, HSGP\n",
    "- Thompson sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost- and response propensity-aware BO \n",
    "\n",
    "#### Varying cost of queries  \n",
    "\n",
    "#### Propensity of response \n",
    "\n",
    "-> possibly provide samples via GitHub & then ask to visualise \n",
    "-> Aalto file sharing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-up \n",
    "\n",
    "Same function as in the ice-breaker; Your turn: query from us function evaluations, and find the maximum of a function, but this time use the science you’ve learnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the different steps of Bayesian optimisation, assume that the unknown function is $f(x) = (6  x - 2)^2  \\sin(12  x - 4)$ (aka Forrester function). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "x_grid <- seq(0, 1, length.out = 100)\n",
    "f_evals <- true_f(x_grid)\n",
    "data_plot <- data.frame(x_grid, f_evals)\n",
    "\n",
    "# Plot the objective function \n",
    "plot <- ggplot(data = data_plot, aes(x = x_grid, y = f_evals)) +\n",
    "  geom_line() +\n",
    "  labs(y = \"f(x)\") +\n",
    "  theme_bw()\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set up a GP surrogate for $f(x)$ as follows: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "y &\\sim \\text{N}(g(x), \\sigma) \\ \\text{with} \\ \\sigma \\sim \\text{N}^+(0,1),\\\\\n",
    "\\\\\n",
    "g(x) &\\sim GP(\\mu, K),  \\text{with} \\ \\mu \\sim \\text{N}(0,1),\\\\ \n",
    "K_{i,j} &= k (x_i, x_j) = \\alpha^2  \\exp \\left(- \\frac{(x_i - x_j)^2}{\\rho^2} \\right),\\\\\n",
    "\\\\\n",
    "\\alpha &\\sim \\text{N}^+(0,1),\\\\ \n",
    "\\rho &\\sim \\text{N}(0.3,0.1).\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Stan, we can implement the model like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(readLines(here::here(\"Stan\", \"fit_gauss_3.stan\")), sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior predictive checks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we have collected any data, we can sample from our priors and check the predictions we would obtain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get samples using chosen priors \n",
    "\n",
    "model_sim <- cmdstanr::cmdstan_model(stan_file = here::here(\"Stan\", \"sim_gauss.stan\"))\n",
    "\n",
    "n_draws <- 15\n",
    "samples <- matrix(NA, nrow = n_draws, ncol=length(x_grid))\n",
    "\n",
    "for (i in 1:n_draws){\n",
    "    # 1. create data input, sample from the chosen priors for fit_gauss_3.stan\n",
    "    stan_dat <- list(N = length(x_grid),\n",
    "                     x = x_grid,\n",
    "                     alpha = abs(rnorm(1)),\n",
    "                     rho = rnorm(1, 0.3, 0.1),\n",
    "                     mu = rnorm(1),\n",
    "                     sigma = abs(rnorm(1, 0.1, 1)))\n",
    "\n",
    "    # 2. sample from model_sim using one chain and iteration, no warmup\n",
    "    gp_priors <- model_sim$sample(data = stan_dat,\n",
    "                                  seed = 424242, \n",
    "                                  iter_sampling = 1, \n",
    "                                  iter_warmup = 0, \n",
    "                                  chains = 1,\n",
    "                                  adapt_engaged=FALSE) # to sample without warmup\n",
    "    # 3. extract corresponding samples\n",
    "    samples[i,] <- gp_priors$draws(\"g\") \n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Visualise the prior predictive results \n",
    "\n",
    "\n",
    "# Extract and reformat samples\n",
    "data <- data.frame(samples[,1:NCOL(samples)])\n",
    "colnames(data) <- sub(\"^X\", \"\", colnames(data))\n",
    "\n",
    "data <- data |>\n",
    "  mutate(draw_id = as.factor(row_number())) |>\n",
    "  pivot_longer(cols = -draw_id, names_to = \"n_evals\", values_to = \"evaluations\") |>\n",
    "  mutate(n_evals = as.integer(n_evals)) |>\n",
    "  nest(data = c(draw_id, evaluations)) |>\n",
    "  mutate(x_grid = x_grid) |>\n",
    "  unnest(cols = c(data))\n",
    "\n",
    "# Plot prior predictives \n",
    "plot_prior_pred <- plot +\n",
    "  geom_line(data = data, aes(x = x_grid, y = evaluations, group = draw_id, color = draw_id, alpha = 0.4)) + \n",
    "  scale_colour_discreterainbow() + \n",
    "  theme(legend.position = \"none\")\n",
    "\n",
    "plot_prior_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
